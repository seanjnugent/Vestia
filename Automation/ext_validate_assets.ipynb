{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data from combined DataFrame:\n",
      "                       Date   Adj_Close       Close        High        Low  \\\n",
      "0 2024-11-01 00:00:00+00:00   97.580002   97.580002   98.300003  97.419998   \n",
      "1 2024-11-04 00:00:00+00:00   98.400002   98.400002   99.879997  98.360001   \n",
      "2 2024-11-05 00:00:00+00:00   99.209999   99.209999  101.089996  98.955002   \n",
      "3 2024-11-06 00:00:00+00:00   96.730003   96.730003   97.320000  94.760002   \n",
      "4 2024-11-07 00:00:00+00:00  100.809998  100.809998  100.830002  99.180000   \n",
      "\n",
      "        Open    Volume Symbol  \n",
      "0  98.220001   8501000   BABA  \n",
      "1  98.820000   8681900   BABA  \n",
      "2  99.970001  10804200   BABA  \n",
      "3  95.800003  18140600   BABA  \n",
      "4  99.260002  11267145   BABA  \n",
      "Data fetch and insertion complete.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Database connection setup\n",
    "db_user = os.getenv(\"DB_USER\")\n",
    "db_password = os.getenv(\"DB_PASSWORD\")\n",
    "db_host = os.getenv(\"DB_HOST\")\n",
    "db_name = os.getenv(\"DB_NAME\")\n",
    "\n",
    "db_url = f\"postgresql+psycopg2://{db_user}:{db_password}@{db_host}/{db_name}\"\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# Fetch symbols from the Asset table in PostgreSQL\n",
    "symbols = []\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT AssetCode FROM Asset where AssetStatus = 'Active'\"))\n",
    "    for row in result:\n",
    "        symbols.append(row[0])\n",
    "\n",
    "# Fetch and process data for each symbol\n",
    "all_data = []\n",
    "\n",
    "for symbol in symbols:\n",
    "    try:\n",
    "        # Download stock data for each symbol\n",
    "        df = yf.download(tickers=symbol, period=\"5d\", interval=\"1d\")\n",
    "        \n",
    "        # If no data is returned, skip this symbol\n",
    "        if df.empty:\n",
    "            print(f\"No data for symbol: {symbol}\")\n",
    "            continue\n",
    "\n",
    "        # Keep only relevant columns, rename, and add Symbol column\n",
    "        df = df[['Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume']].copy()\n",
    "        df.columns = ['Adj_Close', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
    "        df['Symbol'] = symbol\n",
    "        df.reset_index(inplace=True)  # Flatten the Date index\n",
    "\n",
    "        all_data.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {symbol}: {e}\")\n",
    "\n",
    "# Combine all data into a single DataFrame with uniform columns\n",
    "if all_data:\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Display a sample to verify data structure\n",
    "    print(\"Sample data from combined DataFrame:\")\n",
    "    print(combined_df.head())\n",
    "\n",
    "    # Define the table structure in PostgreSQL (create if not exists)\n",
    "    table_name = 'pricestaging'\n",
    "    combined_df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "    # Insert or update data in the staging table\n",
    "    combined_df.to_sql(name=table_name, con=engine, if_exists='append', index=False, method='multi')\n",
    "\n",
    "    print(\"Data fetch and insertion complete.\")\n",
    "else:\n",
    "    print(\"No data fetched. Exiting.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
